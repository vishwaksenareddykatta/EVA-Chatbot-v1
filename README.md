# ğŸš€ EVA Chatbot v1 â€” Lightweight, Fast & Intelligent Python AI Assistant

EVA Chatbot v1 is a fully local, real-time conversational assistant powered by Groqâ€™s ultra-fast LLaMA-3.1-8B-Instant model.
It is designed for speed, accuracy, minimal memory usage, and persistent chat history, making it perfect for personal AI terminals, CLI assistants, automation projects, or lightweight server-side bots.


## âœ¨ Key Features
### ğŸ”¹ âš¡ Ultra-Fast Groq Inference
Runs on llama-3.1-8b-instant, giving near-instant responses with low latency.

### ğŸ”¹ ğŸ§  Smart Conversation Memory
Stores chat history in a JSON file and automatically trims messages to keep performance high.

### ğŸ”¹ ğŸ“… Real-Time Awareness
Injects current day, date, and time into the system prompt for smarter, context-aware replies.

### ğŸ”¹ ğŸ” Optimized Response Engine

Includes:
Automatic empty-line cleanup
Temperature & top-p tuned for balanced creativity
Lightweight LRU caching (@lru_cache) for repeated queries

### ğŸ”¹ ğŸ” Env-Based Configuration

Your:

Username
Assistant name
Groq API key

â€¦are safely loaded from a .env file.

### ğŸ”¹ ğŸ’¾ Automatic Log Persistence
Chat messages (up to last 10) are saved locally without slowing down responses.

### ğŸ”¹ ğŸ’¬ Command-Line Interface
Run the chatbot directly in the terminal â€” simple, clean, always ready.


## ğŸ—‚ï¸ File Overview
chatbot.py â€” Core logic, API calls, chat memory, CLI loop
DataChatLog.json â€” Auto-generated conversation memory
.env â€” Stores environment variables (Username, Assistantname, GroqAPIKey)


## ğŸ› ï¸ Tech Stack
Python 3
Groq API
LLaMA-3.1-8B-Instant
dotenv
LRU Cache
JSON for persistent logs

